---
title: "Use NADA and broom for non-parametric analysis of left-censored groundwater data"
author: "Barbara Monaco"
date: "2/18/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(lubridate)
library(ggplot2)
library(readr)
library(ggthemes)
library(NADA)
library(broom)
library(modelr)

options(scipen = 999)

source('X:/Agency_Files/Solid Waste/C&D Landfills/C&D Groundwater Report_2018/Analysis_Graphics_C&D_Groundwater_Report/R/functions.R')

data <- read_csv("X:/Agency_Files/Solid Waste/C&D Landfills/C&D Groundwater Report_2018/Alex's Files/Combined_data.csv",
                 col_types = cols(
                   FACILITY_CODE = col_character(),
                   SYS_LOC_CODE = col_character(),
                   LOC_NAME = col_character(),
                   SAMPLE_DATE = col_datetime(format = "%Y-%m-%d %H:%M:%S"),
                   LAB_QUALIFIERS = col_character(),
                   REPORTING_DETECTION_LIMIT =col_double(),
                   RESULT_UNIT = col_character(),
                   RESULT_TEXT = col_character(),
                   CONTAMINANT = col_character(),
                   RESULT_NUMERIC = col_double(),
                   DATA_SOURCE = col_character(),
                   PERMIT_NUMBER = col_character(),
                   Well_ID = col_character(),
                   Position = col_factor(),
                   PARAM_CODE = col_character(),
                   ACTION_LEVEL_CODE = col_character(),
                   UNIT = col_character(),
                   EBATCH = col_character(),
                   REMARK = col_character(),
                   MAX_YN = col_character(),
                   EXCEEDANCE_FLAG = col_character(),
                   ACTION_LEVEL = col_double(),
                   WARNING_LEVEL = col_double(),
                   WARNING_LEVEL_MIN = col_double(),
                   ACTION_LEVEL_MIN = col_double(),
                   ACTION_LEVEL_NOTE = col_character(),
                   WARNING_LEVEL_NOTE = col_character(),
                   ACTION_LEVEL_MIN_NOTE = col_character(),
                   WARNING_LEVEL_MIN_NOTE = col_character(),
                   ANALYTIC_METHOD = col_character(),
                   FRACTION = col_character(),
                   MATRIX = col_character(),
                   CUSTOM_FIELD_1 = col_character(),
                   CUSTOM_FIELD_2 = col_character(),
                   CUSTOM_FIELD_3 = col_character(),
                   CUSTOM_FIELD_4 = col_character(),
                   CUSTOM_FIELD_5 = col_character(),
                   EUID = col_character(),
                   LOOKUP_SOURCE = col_character(),
                   LOOKUP_CODE = col_character(),
                   LOOKUP_METHOD = col_character(),
                   MASTER_AI_NAME = col_character())
)

# Add additional calculated data fields -----------------------------------

data <- mutate(data, REPORT_VALUE = ifelse(is.na(RESULT_NUMERIC), 
                                           REPORTING_DETECTION_LIMIT, 
                                           RESULT_NUMERIC),
               CENSORED = ifelse(!is.na(RESULT_NUMERIC), FALSE,
                                 ifelse(!is.na(REPORTING_DETECTION_LIMIT), 
                                        TRUE, NA)),
               Year = lubridate::year(SAMPLE_DATE),
               Month = month(SAMPLE_DATE, label = TRUE))

# We have to put everything in the same units, so we are using ug/L
data <- mutate(data, 
               REPORT_VALUE_ug_L = ifelse(RESULT_UNIT == 'mg/L', 
                                          REPORT_VALUE * 1000, 
                                          REPORT_VALUE),
               REPORT_LIMIT_ug_L = ifelse(RESULT_UNIT == 'mg/L', 
                                          REPORTING_DETECTION_LIMIT * 1000, 
                                          REPORTING_DETECTION_LIMIT),
               HT_ug_L = ifelse(ACTION_LEVEL_CODE == 'MCL_IL', 
                                ACTION_LEVEL * 1000, 
                                ACTION_LEVEL),
               IL_ug_L = ifelse(ACTION_LEVEL_CODE == 'MCL_IL', 
                                WARNING_LEVEL * 1000, 
                                WARNING_LEVEL),
               IL_Detect = ifelse(IL_ug_L > REPORT_LIMIT_ug_L, "Yes", "No"))



# Subset data for analysis ------------------------------------------------
# Eliminate sidegradient as it in not used in the analysis (only up and down)
# If there is data where censorship cannot be determined (i.e. no RL), exclude
# Limit the data to only data collected between 2010 and 2017
# Remove facilities that have only downgradient wells and no upgradient
data_subset <- data %>% select(PERMIT_NUMBER,SYS_LOC_CODE,Well_ID,Position,
                               SAMPLE_DATE,Year, Month, CONTAMINANT,
                               HT_ug_L,IL_ug_L,REPORT_VALUE_ug_L,
                               REPORT_LIMIT_ug_L, CENSORED, IL_Detect) %>% 
  filter(Position != 'Sidegradient',
         !(is.na(CENSORED)),
         Year %in% c(2010:2017),
         !(PERMIT_NUMBER %in% c('SW-501', 'SW-511', 'SW-277', 'SW-407',
                                'SW-412', 'SW-556'))) 
```
## Groundwater impacts of unlined construction and demolition debris landfilling

[This report](https://www.pca.state.mn.us/sites/default/files/w-sw5-54a.pdf) explores the groundwater impacts of unlined construction and demolition (C&D) debris landfills by analyzing self-reported data from 43 C&D landfills, from 2010-2017, with special evaluations of three contaminants of concern (COC): arsenic, boron, and manganese.

We have small data sets and unknown distributions for the COC in groundwater thus we felt that a nonparametric approach was appropriate. Since we have left-censored data and also a variety of reporting limits (RLs), we used the Peto-Prentice Generalized Wilcoxon test which allows us to use the information in the censored data and does not require a single RL. The Peto-Prentice Generalized Wilcoxon is a special case of the general class of weighted log-rank tests
which are nonparametric score tests used to determine whether the distribution functions differ
between groups. 

## Using the NADA package for comparing upgradient vs downgradient concentrations of COC

In order to compare the upgradient vs downgradient concentrations for each COC for each facility, we needed to figure out a smart way of running the analysis on each combination. We also wanted to store the results and summarize them into tables and figures for our paper. The `NADA` package has the functions that we want but can be difficult to get answers out of so if we combine that with the functions in `broom` we can easily get the answers we need by turning models into tidy data.

We are going to be using the approach that Grolemund and Wickham demonstrates in their book "R for Data Science" shown [here](https://r4ds.had.co.nz/many-models.html). The approach starts by creating nested data sets which are then analyzed and the results are stored. We want to nest by facility and contaminant:

```{r}
# Kaplan Meier and Peto-Prentice generalized Wilcoxon ---------------------------------------------------
# using the NADA package by Dennis Helsel, we create a nested tibble and then
# apply the cendiff and cenfit functions to each facility and contaminant

by_facility_contaminant <- data_subset %>% 
  group_by(PERMIT_NUMBER, CONTAMINANT) %>% 
  nest()

```

This creates a data frame that has one row per group (per facility and contaminant), and a column called `data`. `data` contains all the raw data for each group in a tibble and stores the tibbles in a list. Now that we have the nested data frame, we want to apply the generalized wilcoxon to each data frame in the list. We can do this by using the `map` function from the `purrr` package.

The `map` functions transform their input by applying a function to each element and returning a vector the same length as the input. So we need to create a function that takes our data and applies the `cendiff` function to it so all it needs to take is the data frame.
``` {r}
gen_wilcoxon <- function(df) {
  cendiff(obs = df$REPORT_VALUE_ug_L,
          censored = df$CENSORED,
          groups = df$Position)
}
```

We do something similar for fitting the Kaplan-Meier as well. Once these functions are created and applied we need to pull out the elements from them using functions in the `broom` package. `glance` and `tidy` will help extract key pieces of information.

```{r, warning = FALSE}
by_facility_contaminant <- by_facility_contaminant %>% 
  mutate(gen_wilcoxon = map(data, gen_wilcoxon),
         kaplan_meier = map(data, kaplan_meier),
         glance = map(gen_wilcoxon, broom::glance),
         tidy = map(gen_wilcoxon, broom::tidy))
```

In order to look at the nested output, you have to pull out an element from the list. You can do this by calling one of the columns by name and then grabbing the first element in the list by using `[[]]`. For more information on accessing elements in a list, see [R Tutorial - List](http://www.r-tutor.com/r-introduction/list)
```{r}
by_facility_contaminant$gen_wilcoxon[[1]]
by_facility_contaminant$glance[[1]]
by_facility_contaminant$tidy[[1]]
```

Now that we see how the data is structured, we need to unnest the data and pull out the necessary information. Because `tidy` and `glance` have different numbers of rows, we need to make them match. Good news, since we really only care about the observed and expected values for the Upgradient samples, we can filter so we have one row when we unnest `tidy`.

```{r}
results <- by_facility_contaminant %>% 
  unnest(tidy) %>% 
  filter(`df$Position` == 'Upgradient') %>% 
  unnest(glance) %>% 
  mutate(sig_diff = ifelse(obs<exp & (p.value/2) < 0.05, TRUE, FALSE))

head(results %>% select(-data, -gen_wilcoxon,
                        -kaplan_meier, -`df$Position`))
```

But what if we can't filter so that they match? If you create two separate dataset then you can unnest and merge them together. `results_raw` is the results from `broom::tidy` and `results_test` are from `broom::glance`

```{r, warning = FALSE}
# Create contaminant specific datasets ------------------------------------

results_raw <- by_facility_contaminant %>% 
  mutate(tidy = map(gen_wilcoxon, broom::tidy)) %>% 
  unnest(tidy) %>% 
  select(PERMIT_NUMBER, CONTAMINANT, Position = `df$Position`, N, obs, exp)

results_test <- by_facility_contaminant %>% 
  mutate(glance = map(gen_wilcoxon, broom::glance)) %>% 
  unnest(glance)

results_df <- data.table::dcast(setDT(results_raw), PERMIT_NUMBER + CONTAMINANT ~ Position, 
      value.var = c("N", "obs", "exp"))
results_df <- inner_join(results_df, results_test, 
                       by = c("PERMIT_NUMBER", "CONTAMINANT")) %>% 
  mutate(sig_diff = ifelse(obs_Upgradient<exp_Upgradient & (p.value/2) < 0.05,
                           'Yes', "No")) %>% 
  select(-data, -gen_wilcoxon, -kaplan_meier, -tidy, -df)

head(results_df)
```
Once we know which facilities and contaminants are showing a statistically significant increase downgradient, we then evaluate the downgradient samples for exceedances of either the intervention limit (IL) or the health threshold (HT). 

```{r}
exceedance <- left_join(data_subset, results_df, 
                        by = c("PERMIT_NUMBER", "CONTAMINANT")) %>% 
  filter(sig_diff == 'Yes',
         Position == 'Downgradient') %>% 
  mutate(Exceeds = ifelse(REPORT_VALUE_ug_L > HT_ug_L & CENSORED == FALSE, "HT",
                          ifelse(REPORT_VALUE_ug_L > IL_ug_L & CENSORED == FALSE, "IL",
                                 "No Exceedance determined"))) %>% 
  group_by(PERMIT_NUMBER,CONTAMINANT, Exceeds) %>%
  dplyr::summarise(Count = n()) %>% 
  data.table() %>% 
  dcast(PERMIT_NUMBER+CONTAMINANT~Exceeds, value.var = 'Count') %>% 
  rowwise() %>% 
  mutate(total = sum(HT, IL, `No Exceedance determined`, na.rm = TRUE)) %>% 
  as.data.frame()
```

```{r}
exceedance %>% 
  group_by(CONTAMINANT) %>% 
  dplyr::summarise(HT = sum(HT, na.rm = TRUE), 
            IL = sum(IL, na.rm = TRUE),
            No_Exceedance = sum(`No Exceedance determined`, na.rm = TRUE), 
            Total = sum(total, na.rm = TRUE))
```

